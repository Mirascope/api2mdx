---
# AUTO-GENERATED API DOCUMENTATION - DO NOT EDIT
title: responses
description: API documentation for responses
---

# responses

The Responses module for LLM responses.

## <ApiType type="Alias" path="responses/index" symbolName="AsyncContextStream" /> AsyncContextStream

An asynchronous stream of response chunks from an LLM with context.

## <ApiType type="Alias" path="responses/index" symbolName="AsyncContextStructuredStream" /> AsyncContextStructuredStream

An asynchronous stream of partial structured outputs from an LLM with context.

## <ApiType type="Alias" path="responses/index" symbolName="AsyncStream" /> AsyncStream

An asynchronous stream of response chunks from an LLM.

## <ApiType type="Alias" path="responses/index" symbolName="AsyncStructuredStream" /> AsyncStructuredStream

An asynchronous stream of partial structured outputs from an LLM.

## <ApiType type="Alias" path="responses/index" symbolName="ContextResponse" /> ContextResponse

The response generated by an LLM.

## <ApiType type="Alias" path="responses/index" symbolName="ContextStream" /> ContextStream

A synchronous stream of response chunks from an LLM with context.

## <ApiType type="Alias" path="responses/index" symbolName="ContextStreamChunk" /> ContextStreamChunk

A chunk of a streaming response from a contextual LLM call.

## <ApiType type="Alias" path="responses/index" symbolName="ContextStructuredStream" /> ContextStructuredStream

A synchronous stream of partial structured outputs from an LLM with context.

## <ApiType type="Alias" path="responses/index" symbolName="FinishReason" /> FinishReason

The reason why the LLM finished generating a response.

## <ApiType type="Alias" path="responses/index" symbolName="Response" /> Response

The response generated by an LLM.

## <ApiType type="Alias" path="responses/index" symbolName="Stream" /> Stream

A synchronous stream of response chunks from an LLM.

## <ApiType type="Alias" path="responses/index" symbolName="StreamChunk" /> StreamChunk

A chunk of a streaming response from an LLM.

## <ApiType type="Alias" path="responses/index" symbolName="StructuredStream" /> StructuredStream

A synchronous stream of partial structured outputs from an LLM.

## <ApiType type="Alias" path="responses/index" symbolName="Usage" /> Usage

The usage statistics for a request to an LLM.

## <ApiType type="Module" path="responses/index" symbolName="context_response" /> context_response

Interfaces for LLM responses with context.

## <ApiType type="Module" path="responses/index" symbolName="async_context_structured_stream" /> async_context_structured_stream

Interface for streaming structured responses asynchronously with context from LLMs.

## <ApiType type="Module" path="responses/index" symbolName="context_structured_stream" /> context_structured_stream

Interface for streaming structured responses with context from LLMs.

## <ApiType type="Module" path="responses/index" symbolName="context_stream" /> context_stream

Interface for streaming responses with context from LLMs.

## <ApiType type="Module" path="responses/index" symbolName="base_response" /> base_response

The `BaseResponse` class for LLM responses.

## <ApiType type="Module" path="responses/index" symbolName="stream_chunk" /> stream_chunk

The `StreamChunk` class for handling streamed chunks from LLM calls.

## <ApiType type="Module" path="responses/index" symbolName="response" /> response

Interfaces for LLM responses.

## <ApiType type="Module" path="responses/index" symbolName="stream" /> stream

Interface for streaming responses from LLMs.

## <ApiType type="Module" path="responses/index" symbolName="async_stream" /> async_stream

Interface for streaming responses asynchronously from LLMs.

## <ApiType type="Module" path="responses/index" symbolName="structured_stream" /> structured_stream

Interfaces for streaming structured responses from LLMs.

## <ApiType type="Module" path="responses/index" symbolName="content" /> content

## <ApiType type="Module" path="responses/index" symbolName="context_stream_chunk" /> context_stream_chunk

The `ContextStreamChunk` class for handling streamed chunks from contextual LLM calls.

## <ApiType type="Module" path="responses/index" symbolName="async_structured_stream" /> async_structured_stream

Interfaces for asynchronous streaming structured responses from LLMs.

## <ApiType type="Module" path="responses/index" symbolName="finish_reason" /> finish_reason

The reason the LLM finished generating a response.

## <ApiType type="Module" path="responses/index" symbolName="usage" /> usage

The LLM's usage when generating a response.

## <ApiType type="Module" path="responses/index" symbolName="async_context_stream" /> async_context_stream

Interface for streaming responses asynchronously with context from LLMs.

